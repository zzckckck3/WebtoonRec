{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4673fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부마님 거기 있어줄래요\n",
      "['공주', '당나라', '사랑', '남자', '시대극']\n",
      "2191    공주전쟁 [연재]\n",
      "6952         공주전쟁\n",
      "8187      유니크한 그녀\n",
      "225          연애혁명\n",
      "2332         천일야화\n",
      "5333           여혜\n",
      "Name: 제목, dtype: object\n",
      "[0.29040308 0.29040308 0.28992228 0.27999852 0.26825437 0.26214608]\n",
      "\n",
      "\n",
      "방과 후 전쟁활동\t데드데이즈(DEAD DAYS)\n",
      "['드라마', '바이러스', '생존', '스릴러', '스토리']\n",
      "871         의도적 외면\n",
      "1433    심연의 하늘 시즌4\n",
      "1049            개미\n",
      "631         사람의 조각\n",
      "86             신도림\n",
      "2443       정해진 첫사랑\n",
      "Name: 제목, dtype: object\n",
      "[0.49092318 0.48192445 0.4818589  0.43274684 0.4147308  0.39273807]\n",
      "\n",
      "\n",
      "방과 후 전쟁활동\t데드데이즈(DEAD DAYS)\t하이브 3\n",
      "['곤충', '드라마', '바이러스', '전쟁', '생존']\n",
      "2443    정해진 첫사랑\n",
      "1211        개장수\n",
      "236        정글쥬스\n",
      "4018     스킵과 로퍼\n",
      "86          신도림\n",
      "5312    리턴 서바이벌\n",
      "Name: 제목, dtype: object\n",
      "[0.31611797 0.31422747 0.30547959 0.2889469  0.26522074 0.25215486]\n",
      "\n",
      "\n",
      "방과 후 전쟁활동\t데드데이즈(DEAD DAYS)\t하이브 3\t개장수\n",
      "['곤충', '바이러스', '생존', '수가', '스릴러']\n",
      "871          의도적 외면\n",
      "1433     심연의 하늘 시즌4\n",
      "1486        하이브 1~2\n",
      "1792              연\n",
      "6282             파동\n",
      "475     어느날 갑자기 서울은\n",
      "Name: 제목, dtype: object\n",
      "[0.32577347 0.31199883 0.30114998 0.29720821 0.29383815 0.28983884]\n",
      "\n",
      "\n",
      "부마님 거기 있어줄래요\t공주님 마음대로!\t너와 사는 오늘\t우리 내일 이혼해요\tN번째 연애\n",
      "['구한', '당나라', '사랑', '결심', '소꿉친구']\n",
      "4652                           곱배기 연애\n",
      "6584                 당신의 후회는 받지 않겠습니다\n",
      "4050                    별빛 아래 우리 [연재]\n",
      "3700                월식(Lunar Eclipse)\n",
      "7340                    아무것도 하고 싶지 않아\n",
      "3807    저, 능력은 평균치로 해달라고 말했잖아요! (코믹스)\n",
      "Name: 제목, dtype: object\n",
      "[0.2613521  0.26015086 0.2485784  0.24801149 0.24760716 0.24727262]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pandas import DataFrame\n",
    "from multipledispatch import dispatch\n",
    "\n",
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        #불용어사전 추가중\n",
    "        with open('C:/Users/user/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "            list_file = f.readlines()\n",
    "        self.stopwords = list_file[0].split(\",\")\n",
    "        \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)      \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence)) \n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n",
    "\n",
    "\n",
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "#TextRank\n",
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 \n",
    "            link_sum = np.sum(A[:,id])\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    \n",
    "    def keywords(self, word_num=5):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        \n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords\n",
    "    \n",
    "data = pd.read_csv('통합_keyword.csv', low_memory=False)\n",
    "row=[]\n",
    "#print(df.tail(5))\n",
    "@dispatch(str)\n",
    "def get_key(str1):\n",
    "    one = data.index[data['제목'] == str1]\n",
    "    key = data.iloc[one[0], 8]\n",
    "    #print(data.iloc[data.index[data['제목'] == str1], 8])\n",
    "    print(str1)\n",
    "    textrank = TextRank(key)\n",
    "    row = [len(data),'추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(textrank.keywords())]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "    print(row[8])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    web_indices = [index[0] for index in sim[2:8]]\n",
    "    print(df['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "@dispatch(str, str)\n",
    "def get_key(str1, str2):\n",
    "    key=  data.iloc[data.index[data['제목'] == str1][0], 8] + data.iloc[data.index[data['제목'] == str2][0], 8]\n",
    "    print(str1 + \"\\t\" + str2)\n",
    "    textrank = TextRank(key)\n",
    "    text_key = textrank.keywords()\n",
    "    row = [len(data), '추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(text_key)]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "    print(row[8])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    web_indices = [index[0] for index in sim[3:9]]\n",
    "    print(df['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "@dispatch(str, str, str)\n",
    "def get_key(str1, str2, str3):\n",
    "    key=  data.iloc[data.index[data['제목'] == str1][0], 8] + data.iloc[data.index[data['제목'] == str2][0], 8] + data.iloc[data.index[data['제목'] == str3][0], 8]\n",
    "    print(str1 + \"\\t\" + str2 + \"\\t\" + str3)\n",
    "    textrank = TextRank(key)\n",
    "    text_key = textrank.keywords()\n",
    "    row = [len(data), '추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(text_key)]\n",
    "    #row = [len(data), '추천키워드', str(text_key)]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "    print(row[8])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    web_indices = [index[0] for index in sim[4:10]]\n",
    "    print(df['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "@dispatch(str, str, str, str)\n",
    "def get_key(str1, str2, str3, str4):\n",
    "    key=  data.iloc[data.index[data['제목'] == str1][0], 8] + data.iloc[data.index[data['제목'] == str2][0], 8] + data.iloc[data.index[data['제목'] == str3][0], 8] + data.iloc[data.index[data['제목'] == str4][0], 8]\n",
    "    print(str1 + \"\\t\" + str2 + \"\\t\" + str3 + \"\\t\" + str4)\n",
    "    textrank = TextRank(key)\n",
    "    text_key = textrank.keywords()\n",
    "    row = [len(data), '추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(text_key)]\n",
    "    #row = [len(data), '추천키워드', str(text_key)]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "    print(row[8])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    web_indices = [index[0] for index in sim[5:11]]\n",
    "    print(df['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "@dispatch(str, str, str, str, str)\n",
    "def get_key(str1, str2, str3, str4, str5):\n",
    "    key = data.iloc[data.index[data['제목'] == str1][0], 8] + data.iloc[data.index[data['제목'] == str2][0], 8] + data.iloc[data.index[data['제목'] == str3][0], 8] + data.iloc[data.index[data['제목'] == str4][0], 8] + data.iloc[data.index[data['제목'] == str5][0], 8]\n",
    "    print(str1 + \"\\t\" + str2 + \"\\t\" + str3 + \"\\t\" + str4 + \"\\t\" + str5)\n",
    "    textrank = TextRank(key)\n",
    "    text_key = textrank.keywords()\n",
    "    row = [len(data), '추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(text_key)]\n",
    "    #row = [len(data), '추천키워드', str(text_key)]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "    print(row[8])\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    web_indices = [index[0] for index in sim[5:11]]\n",
    "    print(df['제목'].iloc[web_indices])\n",
    "    print(str(cosine_sim[index][web_indices]))\n",
    "    \n",
    "get_key('부마님 거기 있어줄래요')\n",
    "print(\"\\n\")\n",
    "get_key('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)')\n",
    "print(\"\\n\")\n",
    "get_key('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)','하이브 3')\n",
    "print(\"\\n\")\n",
    "get_key('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)','하이브 3','개장수')\n",
    "print(\"\\n\")\n",
    "get_key('부마님 거기 있어줄래요', '공주님 마음대로!', '너와 사는 오늘', '우리 내일 이혼해요', 'N번째 연애')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395bb3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
