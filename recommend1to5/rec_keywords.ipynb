{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45661875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Okt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pandas import DataFrame\n",
    "from multipledispatch import dispatch\n",
    "\n",
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.okt = Okt()\n",
    "        #불용어사전 추가중\n",
    "        with open('C:/Users/user/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "            list_file = f.readlines()\n",
    "        self.stopwords = list_file[0].split(\",\")\n",
    "        \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)      \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence != '':\n",
    "                nouns.append(' '.join([noun for noun in self.okt.nouns(str(sentence)) \n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n",
    "\n",
    "\n",
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n",
    "\n",
    "#TextRank\n",
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): \n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 \n",
    "            link_sum = np.sum(A[:,id])\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "            A[:, id] *= -d\n",
    "            A[id, id] = 1\n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) \n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "        \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "\n",
    "        self.rank = Rank()\n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    \n",
    "    def keywords(self, word_num=5):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "\n",
    "        keywords = []\n",
    "        index=[]\n",
    "        \n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "\n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "\n",
    "        return keywords\n",
    "\n",
    "data = pd.read_csv('통합_keyword.csv', low_memory=False)\n",
    "\n",
    "#global key\n",
    "def get_keys(*args):\n",
    "    cnt = 0\n",
    "    row =[]\n",
    "    key_list = []\n",
    "    del_list = []\n",
    "    key = str('')\n",
    "    web_name = str('')\n",
    "    \n",
    "    if(len(args) <= 8):\n",
    "        for k in args:\n",
    "            key += data.iloc[data.index[data['제목'] == args[cnt]][0], 8]\n",
    "            #key_list.append(data.index[data['제목'] == args[cnt]][0])\n",
    "            for s in data.index[data['제목'] == args[cnt]].values:\n",
    "                key_list.append(s)\n",
    "            web_name += (k+'  ')\n",
    "            cnt += 1\n",
    "    else:\n",
    "        for k in range(8):\n",
    "            key += data.iloc[data.index[data['제목'] == args[cnt]][0], 8]\n",
    "            #key_list.append(data.index[data['제목'] == args[cnt]][0])\n",
    "            for s in data.index[data['제목'] == args[cnt]].values:\n",
    "                key_list.append(s)\n",
    "            web_name += (args[cnt]+'  ')\n",
    "            cnt += 1\n",
    "        print(\"최대 8개 작품까지만 등록 가능합니다.\")\n",
    "    key_args = 2*(len(args)-1) + 5\n",
    "    print(web_name + '\\n')\n",
    "    textrank = TextRank(key)\n",
    "    text_key = textrank.keywords(key_args)\n",
    "    \n",
    "    row = [len(data), '추천키워드','작가','장르','줄거리','url','썸네일','플랫폼',str(text_key)]\n",
    "    df = data.append(pd.Series(row, index=data.columns),ignore_index=True)\n",
    "    df.iloc[-1] = row\n",
    "\n",
    "    #print(row[8]) #추천키워드 목록\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf.fit_transform(df['키워드'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    index = len(df)-1\n",
    "    sim = sorted(list(enumerate(cosine_sim[index])), key=lambda x: x[1], reverse=True)\n",
    "    key_list.append(index)\n",
    "\n",
    "    #입력한 작품 제외\n",
    "    for a in key_list:\n",
    "        for j in range(len(sim)):\n",
    "            if(sim[j][0] == a): \n",
    "                del_list.append(j)\n",
    "\n",
    "    #입력한 작품 제외\n",
    "    for idx in sorted(del_list, reverse = True):\n",
    "        del sim[idx]\n",
    "\n",
    "\n",
    "    #추천키워드와 코사인 유사도가 높은 7개 작품 출력\n",
    "    web_indices = [index[0] for index in sim[0:7]]\n",
    "    \n",
    "    for indx in web_indices:\n",
    "        print(df.iloc[indx, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bdc2d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "부마님 거기 있어줄래요  \n",
      "\n",
      "공주전쟁 [연재]\n",
      "공주전쟁\n",
      "유니크한 그녀\n",
      "연애혁명\n",
      "천일야화\n",
      "여혜\n",
      "관리 마츠리카 전기 [연재]\n",
      "\n",
      "\n",
      "방과 후 전쟁활동  데드데이즈(DEAD DAYS)  \n",
      "\n",
      "리턴 서바이벌\n",
      "공부하기 좋은 날\n",
      "리즌\n",
      "의도적 외면\n",
      "심연의 하늘 시즌4\n",
      "개미\n",
      "사람의 조각\n",
      "\n",
      "\n",
      "부마님 거기 있어줄래요  공주님 마음대로!  너와 사는 오늘  \n",
      "\n",
      "솔로가 하는 연애\n",
      "당신만 몰라!\n",
      "대놓고 사내연애\n",
      "그녀는 흡!혈귀\n",
      "헤어진 다음날\n",
      "파멸 엔딩뿐인 악역영애, 맛있는 요리를 만들며 지내겠습니다. [연재]\n",
      "월식(Lunar Eclipse)\n",
      "\n",
      "\n",
      "방과 후 전쟁활동  데드데이즈(DEAD DAYS)  하이브 3  정글쥬스  \n",
      "\n",
      "하이브 1~2\n",
      "신도림\n",
      "심연의 하늘 시즌4\n",
      "캉타우\n",
      "스퍼맨 시즌1\n",
      "트레이스\n",
      "개장수\n",
      "\n",
      "\n",
      "부마님 거기 있어줄래요  공주님 마음대로!  너와 사는 오늘  우리 내일 이혼해요  N번째 연애  유니크한 그녀  방과 후 전쟁활동  심연의 하늘 시즌4  \n",
      "\n",
      "권태\n",
      "당신의 후회는 받지 않겠습니다\n",
      "우연일까?\n",
      "그녀는 흡!혈귀\n",
      "데드데이즈(DEAD DAYS)\n",
      "그대 마음 한 스푼\n",
      "죽고 못사는 연애\n",
      "\n",
      "\n",
      "최대 8개 작품까지만 등록 가능합니다.\n",
      "방과 후 전쟁활동  데드데이즈(DEAD DAYS)  하이브 3  정글쥬스  부마님 거기 있어줄래요  공주님 마음대로!  너와 사는 오늘  우리 내일 이혼해요  \n",
      "\n",
      "개장수\n",
      "심연의 하늘 시즌4\n",
      "당신의 후회는 받지 않겠습니다\n",
      "하이브 1~2\n",
      "우연일까?\n",
      "그녀는 흡!혈귀\n",
      "스퍼맨 시즌1\n"
     ]
    }
   ],
   "source": [
    "get_keys('부마님 거기 있어줄래요')\n",
    "print(\"\\n\")\n",
    "get_keys('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)')\n",
    "print(\"\\n\")\n",
    "get_keys('부마님 거기 있어줄래요', '공주님 마음대로!', '너와 사는 오늘')\n",
    "print(\"\\n\")\n",
    "get_keys('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)','하이브 3','정글쥬스')\n",
    "print(\"\\n\")\n",
    "get_keys('부마님 거기 있어줄래요', '공주님 마음대로!', '너와 사는 오늘', '우리 내일 이혼해요', 'N번째 연애', '유니크한 그녀', '방과 후 전쟁활동', '심연의 하늘 시즌4')\n",
    "print(\"\\n\")\n",
    "get_keys('방과 후 전쟁활동', '데드데이즈(DEAD DAYS)','하이브 3','정글쥬스','부마님 거기 있어줄래요', '공주님 마음대로!', '너와 사는 오늘', '우리 내일 이혼해요', 'N번째 연애', '유니크한 그녀', '심연의 하늘 시즌4', '연애혁명' , '신도림', '하이브 1~2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37683d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af765c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
